% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created Fri Jul 07 21:23:40 IRDT 2017
%
% This script assumes these variables are defined:
%
%   Features_Train - input data.
%   Train_Labels - target data.
Best=0.3;
nBest=0;
for n=5:40 %n=24 best
Error=0;
Error_Val=0;
Error_Train=0;
for k=1:6
x = Features_Train';
t = Train_Labels_M';

% Create a Pattern Recognition Network
hiddenLayerSize = n;
net = patternnet(hiddenLayerSize);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};


% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
% net.divideFcn = 'dividerand';  % Divide data randomly
% net.divideMode = 'sample';  % Divide up every sample
% net.divideParam.trainRatio = 75/100;
% net.divideParam.valRatio = 20/100;
% net.divideParam.testRatio = 5/100;
net.divideFcn = 'divideind'; % Divide data by indices (i.e. not randomly)
Indices = [(k-1)*28+1:k*28];
net.divideParam.valInd = Indices(1:14);
net.divideParam.testInd = Indices(15:28);
FullIdx=1:168;
NotIdx= Indices;
Idx=setdiff(FullIdx,NotIdx);
net.divideParam.trainInd = Idx;




% For help on training function 'trainscg' type: help trainscg
% For a list of all training functions type: help nntrain
net.trainFcn = 'trainscg';  % Scaled conjugate gradient

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  %

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
  'plotregression', 'plotfit'};


% Train the Network
[net,tr] = train(net,x,t);

% Test the Network
y = net(x);
e = gsubtract(t,y);
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);
performance = perform(net,t,y)

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t  .* tr.valMask{1};
testTargets = t  .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y)
valPerformance = perform(net,valTargets,y)
testPerformance = perform(net,testTargets,y)

% View the Network
%view(net)

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)
%figure, ploterrhist(e)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
if (false)
  % Generate MATLAB function for neural network for application deployment
  % in MATLAB scripts or with MATLAB Compiler and Builder tools, or simply
  % to examine the calculations your trained neural network performs.
  genFunction(net,'myNeuralNetworkFunction');
  y = myNeuralNetworkFunction(x);
end
if (false)
  % Generate a matrix-only MATLAB function for neural network code
  % generation with MATLAB Coder tools.
  genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
  y = myNeuralNetworkFunction(x);
end
if (false)
  % Generate a Simulink diagram for simulation or deployment with.
  % Simulink Coder tools.
  gensim(net);
end
Error = Error+performance ;
Error_Val = Error_Val+valPerformance;
Error_Train = Error_Train + trainPerformance ;
 end
 Error_F= Error/k;
 Error_Val_F(n-4) = Error_Val/k;
 Error_Train_F(n-4) = Error_Train/k;
   if (Error_F<Best)
      Best=Error_F;
      nBest=n;
   end
end
